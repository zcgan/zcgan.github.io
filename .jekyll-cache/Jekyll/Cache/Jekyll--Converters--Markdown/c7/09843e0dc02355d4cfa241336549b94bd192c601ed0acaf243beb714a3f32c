I"Î<h2 id="description">Description</h2>
<p>The course mainly covers topics in non-smooth optimization and first-order proximal splitting methods. This includes gradient based methods ((sub)gradient method, proximal gradient method, accelerated gradient methods), operator splitting methods (augmented Lagrangian method, alternating direction method of multipliers, monotone operators and operator splitting schemes), and (possibly) interior-point algorithms. Non-convex optimisation and stochastic optimisation will also be introduced.</p>

<!-- ### Lectures
Lectures are Monday and Wednesday, 11:00â€“12:00am, at MR9, Pav. B0.43.  -->

<h3 id="lecture-slides">Lecture slides</h3>
<ol style="margin-left:12px;">
    <li> <a href="nsopt/slides/introduction.pdf">Introduction</a></li>
    <li> <a href="nsopt/slides/lecture-01.pdf">Gradient method</a></li>
    <li> <a href="nsopt/slides/lecture-02.pdf">Proximal gradient method</a></li>
    <li> <a href="nsopt/slides/lecture-03.pdf">Krasnosel'skii-Mann iteration</a></li>
    <li> <a href="nsopt/slides/lecture-04.pdf">Backward--Backward splitting</a></li>
    <li> <a href="nsopt/slides/lecture-05.pdf">Douglas--Rachford splitting</a></li>
    <li> <a href="nsopt/slides/lecture-06.pdf">Primal--Dual splitting</a></li>
    <li> <a href="nsopt/slides/lecture-07.pdf">Other operator splitting methods</a></li>
    <li> <a href="nsopt/slides/lecture-08.pdf">Alternating direction method of multipliers</a></li>
    <li> <a href="nsopt/slides/lecture-09.pdf">Non-convex optimisation</a></li>
    <li> <a href="nsopt/slides/lecture-10.pdf">Stochastic optimisation</a></li>
</ol>
<!-- 1. [Introduction](nsopt/slides/introduction.pdf)
2. [Gradient method](nsopt/slides/lecture-01.pdf)
3. [Proximal gradient method](nsopt/slides/lecture-02.pdf)
4. [Krasnosel'skii-Mann iteration](nsopt/slides/lecture-03.pdf)
5. [Backward--Backward splitting](nsopt/slides/lecture-04.pdf)
6. [Douglas--Rachford splitting](nsopt/slides/lecture-05.pdf)
7. [Primal--Dual splitting](nsopt/slides/lecture-06.pdf)
8. [Other operator splitting methods](nsopt/slides/lecture-07.pdf)
9. [Alternating direction method of multipliers](nsopt/slides/lecture-08.pdf)
10. [Non-convex optimisation](nsopt/slides/lecture-09.pdf)
11. [Stochastic optimisation](nsopt/slides/lecture-10.pdf) -->

<p><strong>Acknowledgement:</strong> some slides are based on the lecture slides of <a href="https://web.stanford.edu/~boyd/">Prof. Stephen Boyd</a> and <a href="http://www.seas.ucla.edu/~vandenbe/">Prof. Lieven Vandenberghe</a>.</p>

<h3 id="projects">Projects</h3>
<ul>
  <li><a href="nsopt/projects/project-01.pdf">Project 1</a> Comparison of gradient descent, heavy-ball method and Nesterovâ€™s acceleration scheme, and their proximal versions. (<a href="nsopt/project1">Instructions</a>, <a href="nsopt/projects/data.zip">data</a>, <a href="nsopt/projects/src_Project1.zip">MATLAB code</a>)</li>
  <li><a href="nsopt/projects/project-02.pdf">Project 2</a> Principal component pursuit. (<a href="nsopt/project2">Instructions</a>, <a href="nsopt/projects/src_Project2.zip">MATLAB code</a>)</li>
</ul>

<p><br /></p>

<h4 id="references">References</h4>
<ul>
  <li>S. Boyd and L. Vandenberghe. Convex optimization. Cambridge university press, 2004.</li>
  <li>R. T. Rockafellar. Convex analysis. Princeton university press, 2015.</li>
  <li>A. Beck. First-order methods in optimization. Vol. 25. SIAM, 2017.</li>
  <li>H. H. Bauschke and P. L. Combettes. Convex analysis and monotone operator theory in Hilbert spaces. Vol. 408. New York: Springer, 2011.</li>
  <li>B. Polyak. Introduction to optimization. Optimization Software, 1987.</li>
  <li>Y. Nesterov. Introductory lectures on convex optimization: A basic course. Vol. 87. Springer Science &amp; Business Media, 2013.</li>
</ul>

:ET